"""
å›¾ç‰‡å¢å¼ºæ¨¡å— - çœŸå®ä¸–ç•Œæ¨¡æ‹Ÿï¼ˆé€è§†å˜æ¢ã€æ³Šæ¾èåˆç­‰ï¼‰
"""

import cv2
import numpy as np
import json
import os


def load_cached_coordinates(image_path, coord_file):
    """å°è¯•ä»JSONæ–‡ä»¶ä¸­åŠ è½½ç¼“å­˜çš„åæ ‡"""
    if not os.path.exists(coord_file):
        return None

    try:
        with open(coord_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        # ç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ è·¯å¾„ä½œä¸ºkey
        key = image_path.replace("\\", "/")
        if key in data:
            print(f"æ£€æµ‹åˆ°ç¼“å­˜åæ ‡ï¼Œå·²ä» {coord_file} åŠ è½½ã€‚")
            return np.array(data[key], dtype="float32")
    except Exception as e:
        print(f"è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")

    return None


def save_cached_coordinates(image_path, coords, coord_file):
    """å°†æ‰‹å·¥æ ‡è®°çš„åæ ‡ä¿å­˜åˆ°JSONæ–‡ä»¶"""
    data = {}
    # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œå…ˆè¯»å–åŸæœ‰æ•°æ®
    if os.path.exists(coord_file):
        try:
            with open(coord_file, "r", encoding="utf-8") as f:
                data = json.load(f)
        except:
            pass  # å¦‚æœæ–‡ä»¶æŸåï¼Œå°±è¦†ç›–å®ƒ

    # è½¬æ¢ numpy æ•°ç»„ä¸º list ä»¥ä¾¿ JSON åºåˆ—åŒ–
    key = image_path.replace("\\", "/")
    data[key] = coords.tolist()

    try:
        with open(coord_file, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        print(f"å·²å°†åæ ‡ä¿å­˜è‡³ {coord_file}ï¼Œä¸‹æ¬¡è¿è¡Œå°†è‡ªåŠ¨åŠ è½½ã€‚")
    except Exception as e:
        print(f"ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")


def cv_imread(file_path):
    """è¯»å–å«ä¸­æ–‡è·¯å¾„çš„å›¾ç‰‡"""
    return cv2.imdecode(np.fromfile(file_path, dtype=np.uint8), cv2.IMREAD_COLOR)


def order_points(pts):
    """
    é‡æ’åæ ‡ç‚¹é¡ºåºï¼šå·¦ä¸Š, å³ä¸Š, å³ä¸‹, å·¦ä¸‹
    """
    rect = np.zeros((4, 2), dtype="float32")

    # åæ ‡ç‚¹æ±‚å’Œ:
    # å·¦ä¸Šè§’ sum æœ€å°
    # å³ä¸‹è§’ sum æœ€å¤§
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]

    # åæ ‡ç‚¹å·®å€¼ (y - x):
    # å³ä¸Šè§’ diff æœ€å°
    # å·¦ä¸‹è§’ diff æœ€å¤§
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]

    return rect


def detect_document_corners(image_path, coord_file, debug=False):
    """
    æ™ºèƒ½è¯†åˆ«æ–¹æ¡ˆï¼š
    1. ä¼˜å…ˆæ£€æŸ¥æœ¬åœ° JSON æ˜¯å¦æœ‰ç¼“å­˜åæ ‡
    2. å±€éƒ¨å¯¹æ¯”åº¦å¢å¼º + åŒè¾¹æ»¤æ³¢ (é’ˆå¯¹åŒè‰²ç³»èƒŒæ™¯)
    3. Cannyè¾¹ç¼˜æ£€æµ‹
    4. è½®å»“ç­›é€‰ + æœ€å°å¤–æ¥çŸ©å½¢
    5. å¤±è´¥è‡ªåŠ¨è§¦å‘æ‰‹åŠ¨æ¨¡å¼ï¼Œå¹¶ä¿å­˜ç»“æœåˆ° JSON
    """
    # æ­¥éª¤ 0: æ£€æŸ¥ç¼“å­˜
    cached_pts = load_cached_coordinates(image_path, coord_file)
    if cached_pts is not None:
        return order_points(cached_pts)

    image = cv_imread(image_path)
    if image is None:
        print(f"æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
        return None

    # 1. å›¾åƒå¢å¼ºé¢„å¤„ç†
    ratio = image.shape[0] / 800.0
    orig = image.copy()
    processed_img = cv2.resize(image, (int(image.shape[1] / ratio), 800))

    gray = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)

    # åŒè¾¹æ»¤æ³¢ï¼šèƒ½æå¥½åœ°å»é™¤æ¡Œé¢çš„çº¹ç†å™ªç‚¹ï¼ŒåŒæ—¶ä¿ç•™çº¸å¼ è¾¹ç¼˜
    gray = cv2.bilateralFilter(gray, 11, 75, 75)

    # CLAHEï¼šè‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼Œå¢å¼ºå±€éƒ¨å¯¹æ¯”åº¦
    # è¿™å¯¹è¯†åˆ«"ç™½æ¡Œå­ä¸Šçš„ç™½çº¸"è‡³å…³é‡è¦
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    gray = clahe.apply(gray)

    # 2. è¾¹ç¼˜æ£€æµ‹
    # è‡ªåŠ¨è®¡ç®— Canny é˜ˆå€¼
    v = np.median(gray)
    sigma = 0.33
    lower_thresh = int(max(0, (1.0 - sigma) * v))
    upper_thresh = int(min(255, (1.0 + sigma) * v))
    edged = cv2.Canny(gray, lower_thresh, upper_thresh)

    # è†¨èƒ€å¤„ç†ï¼Œè¿æ¥æ–­å¼€çš„è¾¹ç¼˜
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    edged = cv2.dilate(edged, kernel, iterations=1)

    # 3. è½®å»“æå–
    cnts, _ = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]

    screenCnt = None

    print("æ­£åœ¨å°è¯•è‡ªåŠ¨è¯†åˆ«...")
    for c in cnts:
        peri = cv2.arcLength(c, True)
        # è¿‘ä¼¼å¤šè¾¹å½¢
        approx = cv2.approxPolyDP(c, 0.02 * peri, True)

        # åªè¦é¡¶ç‚¹æ•°åœ¨4åˆ°6ä¹‹é—´ï¼Œä¸”é¢ç§¯å¤Ÿå¤§ï¼Œå°±è®¤ä¸ºæ˜¯å€™é€‰çº¸å¼ 
        if 4 <= len(approx) <= 6 and cv2.contourArea(c) > 50000:
            # ä½¿ç”¨æœ€å°å¤–æ¥çŸ©å½¢æ¥è§„æ•´åŒ–ï¼ˆè§£å†³5ã€6ä¸ªç‚¹çš„é—®é¢˜ï¼‰
            rect = cv2.minAreaRect(c)
            box = cv2.boxPoints(rect)
            screenCnt = np.int64(box)
            print(f"-> é”å®šå€™é€‰è½®å»“ï¼Œé¢ç§¯: {cv2.contourArea(c)}")
            break

    # 4. ç»“æœå¤„ç†
    if screenCnt is not None:
        # è¿˜åŸåˆ°åŸå§‹å°ºå¯¸
        detected_pts = (screenCnt * ratio).astype(np.float32)
        ordered_pts = order_points(detected_pts)

        if debug:
            debug_img = orig.copy()
            cv2.polylines(debug_img, [ordered_pts.astype(int)], True, (0, 255, 0), 3)
            debug_path = "output/03_simulated/debug_detection.jpg"
            os.makedirs(os.path.dirname(debug_path), exist_ok=True)
            cv2.imwrite(debug_path, debug_img)
            print("è‡ªåŠ¨è¯†åˆ«æˆåŠŸï¼è°ƒè¯•å›¾: debug_detection.jpg")

        return ordered_pts
    else:
        # 5. å…œåº•æ–¹æ¡ˆï¼šæ‰‹åŠ¨è¯†åˆ«
        manual_pts = manual_select_corners(orig)
        if manual_pts is not None:
            # å¦‚æœæ˜¯ç”¨æˆ·æ‰‹å·¥è¾›è‹¦æ ‡çš„ï¼Œæˆ‘ä»¬æŠŠå®ƒå­˜ä¸‹æ¥
            save_cached_coordinates(image_path, manual_pts, coord_file)
        return manual_pts


def manual_select_corners(image):
    """
    å½“è‡ªåŠ¨è¯†åˆ«å¤±è´¥æ—¶ï¼Œå¼¹å‡ºçª—å£è®©ç”¨æˆ·æ‰‹åŠ¨ç‚¹å‡»4ä¸ªè§’
    """
    print("\n" + "=" * 50)
    print("ã€è¿›å…¥æ‰‹åŠ¨è¾…åŠ©æ¨¡å¼ã€‘")
    print("è‡ªåŠ¨è¯†åˆ«æœªæ‰¾åˆ°ç†æƒ³ç»“æœã€‚")
    print("æ“ä½œè¯´æ˜ï¼š")
    print("1. è¯·åœ¨æ–°å¼¹å‡ºçš„ 'Manual Selection' çª—å£ä¸­ã€‚")
    print("2. ä¾æ¬¡ç‚¹å‡»çº¸å¼ çš„ã€å››ä¸ªé¡¶ç‚¹ã€‘ï¼ˆé¡ºåºä¸é™ï¼‰ã€‚")
    print("3. ç‚¹é”™è¯·æŒ‰ 'r' é”®é‡ç½®ï¼Œæ»¡æ„è¯·æŒ‰ä»»æ„é”®ç¡®è®¤ã€‚")
    print("=" * 50 + "\n")

    # ç¼©æ”¾ä»¥é€‚åº”å±å¹•æ˜¾ç¤º (é¿å… 4K å›¾å¤ªå¤§)
    h, w = image.shape[:2]
    scale = 1.0
    if h > 900:
        scale = 900.0 / h

    disp_w, disp_h = int(w * scale), int(h * scale)
    display_img = cv2.resize(image, (disp_w, disp_h))
    temp_img = display_img.copy()  # ç”¨äºç”»ç‚¹çš„ä¸´æ—¶å›¾

    points = []

    def mouse_callback(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            if len(points) < 4:
                # è®°å½•ç‚¹å‡»åæ ‡ï¼ˆè¿˜åŸå›åŸå›¾å°ºåº¦ï¼‰
                real_x = int(x / scale)
                real_y = int(y / scale)
                points.append([real_x, real_y])

                # è§†è§‰åé¦ˆï¼šåœ¨æ˜¾ç¤ºå›¾ä¸Šç”»çº¢ç‚¹
                cv2.circle(temp_img, (x, y), 8, (0, 0, 255), -1)
                # ç”»å‡ºåæ ‡åºæ•°
                cv2.putText(temp_img, str(len(points)), (x + 10, y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                cv2.imshow("Manual Selection", temp_img)

    cv2.namedWindow("Manual Selection", cv2.WINDOW_AUTOSIZE)
    cv2.setMouseCallback("Manual Selection", mouse_callback)
    cv2.imshow("Manual Selection", display_img)

    # ç­‰å¾…ç”¨æˆ·äº¤äº’
    final_pts = None
    while True:
        key = cv2.waitKey(20) & 0xFF

        # æŒ‰ 'r' é‡ç½®
        if key == ord('r'):
            points = []
            temp_img = display_img.copy()
            cv2.imshow("Manual Selection", temp_img)
            print(">> å·²é‡ç½®ï¼Œè¯·é‡æ–°ç‚¹å‡»")

        # æŒ‰ 'q' å¼ºåˆ¶é€€å‡º
        if key == ord('q'):
            print(">> ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            break

        # å¦‚æœç‚¹æ»¡4ä¸ªç‚¹ï¼Œä¸”æŒ‰ä¸‹äº†ä»»æ„é”® (é™¤äº†r/q)ï¼Œåˆ™ç¡®è®¤
        # æˆ–è€…ä¸ºäº†æ–¹ä¾¿ï¼Œç‚¹æ»¡4ä¸ªç‚¹è‡ªåŠ¨æš‚åœç­‰å¾…ç¡®è®¤
        if len(points) == 4:
            # åœ¨å›¾ä¸Šæç¤º"æŒ‰ä»»æ„é”®ç¡®è®¤"
            cv2.putText(temp_img, "Press ANY key to Confirm", (20, 50),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 3)
            cv2.imshow("Manual Selection", temp_img)

            # ç­‰ç”¨æˆ·æŒ‰é”®
            key2 = cv2.waitKey(0) & 0xFF
            if key2 == ord('r'):
                # å¦‚æœç”¨æˆ·è¿™æ—¶æŒ‰äº†rï¼Œåˆ™é‡ç½®ï¼Œä¸é€€å‡º
                points = []
                temp_img = display_img.copy()
                cv2.imshow("Manual Selection", temp_img)
                continue
            else:
                final_pts = np.array(points, dtype="float32")
                break

    cv2.destroyAllWindows()

    if final_pts is not None:
        return order_points(final_pts)
    return None


def _auto_rotate_to_match_orientation(src, dst_corners):
    """
    æ£€æŸ¥æºå›¾ä¸ç›®æ ‡åŒºåŸŸçš„æ–¹å‘ï¼ˆæ¨ªç‰ˆ/ç«–ç‰ˆï¼‰æ˜¯å¦ä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´åˆ™è‡ªåŠ¨æ—‹è½¬æºå›¾90åº¦ã€‚
    """
    # è®¡ç®—ç›®æ ‡åŒºåŸŸçš„å¤§è‡´å®½é«˜
    (tl, tr, br, bl) = dst_corners
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    dst_w = max(int(widthA), int(widthB))

    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    dst_h = max(int(heightA), int(heightB))

    h_src, w_src = src.shape[:2]

    # åˆ¤æ–­æ˜¯å¦ä¸ºæ¨ªç‰ˆ (Width > Height)
    src_is_landscape = w_src > h_src
    dst_is_landscape = dst_w > dst_h

    if src_is_landscape != dst_is_landscape:
        print(f"   [è‡ªåŠ¨æ—‹è½¬] æ–¹å‘ä¸åŒ¹é… (Srcæ¨ªç‰ˆ={src_is_landscape}, Dstæ¨ªç‰ˆ={dst_is_landscape})ï¼Œæ‰§è¡Œæ—‹è½¬...")
        src = cv2.rotate(src, cv2.ROTATE_90_CLOCKWISE)

    return src


def _pad_src_to_match_ratio(src, dst_corners):
    """
    ä¸ºäº†é˜²æ­¢ç”µå­å‡­è¯è¢«æ‹‰ä¼¸/æŒ¤å‹å˜å½¢ï¼Œæˆ‘ä»¬éœ€è¦å…ˆç»™æºå›¾è¡¥ç™½è¾¹ï¼Œ
    ä½¿å…¶å®½é«˜æ¯”(Aspect Ratio)ä¸ç›®æ ‡åŒºåŸŸçš„é€è§†å®½é«˜æ¯”å¤§è‡´ä¸€è‡´ã€‚
    """
    # 1. è®¡ç®—ç›®æ ‡åŒºåŸŸç›®å‰çš„"ç‰©ç†"å®½é«˜è¿‘ä¼¼å€¼
    # ç”±äºæœ‰é€è§†ï¼Œæˆ‘ä»¬å–ä¸¤ç»„è¾¹é•¿çš„æœ€å¤§å€¼ä½œä¸ºå‚è€ƒ
    (tl, tr, br, bl) = dst_corners
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))

    dst_ratio = maxWidth / float(maxHeight)

    h_src, w_src = src.shape[:2]
    src_ratio = w_src / float(h_src)

    print(f"   [æ¯”ä¾‹æ ¡æ­£] Srcæ¯”ä¾‹: {src_ratio:.2f}, DståŒºåŸŸæ¯”ä¾‹: {dst_ratio:.2f}")

    # 2. æ ¹æ®æ¯”ä¾‹å·®å¼‚è¿›è¡Œå¡«å……
    pad_h, pad_w = 0, 0

    if abs(src_ratio - dst_ratio) < 0.1:
        # å¦‚æœæ¯”ä¾‹å·®ä¸å¤šï¼Œå°±ä¸åŠ¨äº†
        return src

    if src_ratio > dst_ratio:
        # æºå›¾æ¯”ç›®æ ‡æ›´"æ‰/èƒ–"ï¼Œç›®æ ‡æ¯”è¾ƒ"ç˜¦/é«˜"
        # è¿™ç§æƒ…å†µä¸‹ï¼Œæºå›¾éœ€è¦ä¸Šä¸‹è¡¥ç™½ï¼Œå˜é«˜ä¸€ç‚¹ï¼Œæ‰èƒ½å¡è¿›å»ä¸å˜å½¢
        new_h = int(w_src / dst_ratio)
        total_pad = new_h - h_src
        pad_top = total_pad // 2
        pad_bot = total_pad - pad_top

        # ä½¿ç”¨ç™½è‰²å¡«å…… (255, 255, 255)
        src_padded = cv2.copyMakeBorder(src, pad_top, pad_bot, 0, 0, cv2.BORDER_CONSTANT, value=(255, 255, 255))
        print(f"   [æ¯”ä¾‹æ ¡æ­£] ä¸ºæºå›¾ä¸Šä¸‹è¡¥ç™½: {total_pad}px")

    else:
        # æºå›¾æ¯”ç›®æ ‡æ›´"ç˜¦/é«˜"ï¼Œç›®æ ‡æ¯”è¾ƒ"æ‰/èƒ–" (è¿™æ˜¯æ‚¨é‡åˆ°çš„æƒ…å†µ)
        # è¿™ç§æƒ…å†µä¸‹ï¼Œæºå›¾éœ€è¦å·¦å³è¡¥ç™½ï¼Œå˜å®½ä¸€ç‚¹
        new_w = int(h_src * dst_ratio)
        total_pad = new_w - w_src
        pad_left = total_pad // 2
        pad_right = total_pad - pad_left

        src_padded = cv2.copyMakeBorder(src, 0, 0, pad_left, pad_right, cv2.BORDER_CONSTANT, value=(255, 255, 255))
        print(f"   [æ¯”ä¾‹æ ¡æ­£] ä¸ºæºå›¾å·¦å³è¡¥ç™½: {total_pad}px")

    return src_padded


def _base_synthesis_pipeline(src_path, dst_path, dst_corners, output_path, mode="normal",
                            enable_ratio_fix=False, enable_auto_rotate=True):
    """
    åŸºç¡€åˆæˆæµæ°´çº¿
    """
    # 1. è¯»å–å›¾åƒ
    src = cv_imread(src_path)
    dst = cv_imread(dst_path)
    if src is None or dst is None:
        print(f"é”™è¯¯ï¼šæ— æ³•è¯»å–å›¾ç‰‡ã€‚\nSrc: {src_path}\nDst: {dst_path}")
        return

    # [æ–°å¢] è‡ªåŠ¨æ—‹è½¬æ ¡æ­£æ–¹å‘
    if enable_auto_rotate:
        src = _auto_rotate_to_match_orientation(src, dst_corners)

    # [æ–°å¢] æ¯”ä¾‹è‡ªé€‚åº”æ ¡æ­£
    if enable_ratio_fix:
        src = _pad_src_to_match_ratio(src, dst_corners)

    # 2. å‡†å¤‡é€è§†å˜æ¢
    h_src, w_src = src.shape[:2]
    src_pts = np.array([[0, 0], [w_src - 1, 0], [w_src - 1, h_src - 1], [0, h_src - 1]], dtype="float32")
    dst_pts = np.array(dst_corners, dtype="float32")

    M = cv2.getPerspectiveTransform(src_pts, dst_pts)
    warped_src = cv2.warpPerspective(src, M, (dst.shape[1], dst.shape[0]))

    # 3. åˆ›å»ºæ©æ¨¡
    mask = np.zeros(dst.shape[:2], dtype=np.uint8)
    cv2.fillConvexPoly(mask, dst_pts.astype(int), 255)

    # 4. è‰²å½©ç©ºé—´åŒ¹é…
    dst_lab = cv2.cvtColor(dst, cv2.COLOR_BGR2LAB)
    warped_lab = cv2.cvtColor(warped_src, cv2.COLOR_BGR2LAB)

    dst_region_l = dst_lab[:, :, 0][mask > 0]
    if dst_region_l.size == 0:
        print("è­¦å‘Šï¼šç›®æ ‡åŒºåŸŸæ©æ¨¡ä¸ºç©º")
        return

    l_mean_dst, l_std_dst = np.mean(dst_region_l), np.std(dst_region_l)
    src_region_l = warped_lab[:, :, 0][mask > 0]
    l_mean_src, l_std_src = np.mean(src_region_l), np.std(src_region_l)

    # é’ˆå¯¹ä¸åŒæ¨¡å¼ï¼Œå¾®è°ƒå…‰ç…§å‚æ•° (ç¤ºä¾‹)
    contrast_factor = 1.0
    if mode == "shadow":
        contrast_factor = 0.85  # é˜´å½±ä¸‹å¯¹æ¯”åº¦ä½ä¸€ç‚¹å¯èƒ½æ›´è‡ªç„¶
    elif mode == "tilted":
        contrast_factor = 0.95

    l_channel = warped_lab[:, :, 0].astype(float)
    l_channel = (l_channel - l_mean_src) * (l_std_dst / (l_std_src + 1e-5)) * contrast_factor + l_mean_dst
    warped_lab[:, :, 0] = np.clip(l_channel, 0, 255).astype(np.uint8)

    matched_src = cv2.cvtColor(warped_lab, cv2.COLOR_LAB2BGR)

    # 5. æ³Šæ¾èåˆ
    center = (int((dst_pts[:, 0].min() + dst_pts[:, 0].max()) / 2),
              int((dst_pts[:, 1].min() + dst_pts[:, 1].max()) / 2))

    clone_mode = cv2.NORMAL_CLONE

    try:
        final_output = cv2.seamlessClone(matched_src, dst, mask, center, clone_mode)
    except Exception as e:
        print(f"èåˆå¤±è´¥ï¼Œé™çº§ä¸ºç›´æ¥è¦†ç›–: {e}")
        final_output = dst.copy()
        final_output[mask > 0] = matched_src[mask > 0]

    # 6. ä¿å­˜
    cv2.imwrite(output_path, final_output)
    print(f"æˆåŠŸï¼åˆæˆå›¾å·²ä¿å­˜è‡³: {output_path}")


def process_scene_by_filename(src_path, dst_path, dst_corners, output_path, bg_filename, mode="normal"):
    """
    æ ¹æ®èƒŒæ™¯æ–‡ä»¶åé€‰æ‹©å¯¹åº”çš„åœºæ™¯å¤„ç†å‡½æ•°
    """
    print(f"\n>>> æ­£åœ¨åˆæˆ: {os.path.basename(src_path)} -> {bg_filename}")
    _base_synthesis_pipeline(src_path, dst_path, dst_corners, output_path,
                           mode=mode, enable_ratio_fix=True, enable_auto_rotate=True)


class ImageAugmenter:
    """å›¾ç‰‡å¢å¼ºå™¨ - çœŸå®ä¸–ç•Œæ¨¡æ‹Ÿ"""

    def __init__(self, backgrounds_dir: str, output_dir: str, coord_file: str = "coordinates_cache.json"):
        """
        åˆå§‹åŒ–å›¾ç‰‡å¢å¼ºå™¨

        Args:
            backgrounds_dir: èƒŒæ™¯å›¾ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            coord_file: åæ ‡ç¼“å­˜æ–‡ä»¶
        """
        self.backgrounds_dir = backgrounds_dir
        self.output_dir = output_dir
        self.coord_file = coord_file

    def process_images(self, src_dir: str):
        """
        æ‰¹é‡å¤„ç†å›¾ç‰‡

        Args:
            src_dir: æºå›¾ç‰‡ç›®å½•
        """
        # æ£€æŸ¥æºæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(src_dir):
            print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {src_dir}")
            return

        # æ£€æŸ¥èƒŒæ™¯æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.backgrounds_dir):
            print(f"âŒ èƒŒæ™¯ç›®å½•ä¸å­˜åœ¨: {self.backgrounds_dir}")
            return

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)

        # è·å–æºæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰å›¾ç‰‡ (æ”¯æŒ jpg, jpeg, png)
        src_files = [f for f in os.listdir(src_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        src_files.sort()

        # è·å–èƒŒæ™¯æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰å›¾ç‰‡
        bg_files = [f for f in os.listdir(self.backgrounds_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        bg_files.sort()

        print(f"æ‰¾åˆ° {len(src_files)} å¼ æºå›¾ç‰‡")
        print(f"æ‰¾åˆ° {len(bg_files)} å¼ èƒŒæ™¯å›¾å¾…å¤„ç†")

        # å¤–å±‚å¾ªç¯ï¼šéå†æ¯ä¸€å¼ æºå›¾ç‰‡
        for src_file in src_files:
            src_img_path = os.path.join(src_dir, src_file)
            src_base_name = os.path.splitext(src_file)[0]

            print(f"\n{'='*60}")
            print(f"ã€å¼€å§‹å¤„ç†æºæ–‡ä»¶ã€‘: {src_file}")
            print(f"{'='*60}")

            # å†…å±‚å¾ªç¯ï¼šéå†æ¯ä¸€ä¸ªèƒŒæ™¯å›¾
            for bg_file in bg_files:
                dst_img_path = os.path.join(self.backgrounds_dir, bg_file)

                # æå–èƒŒæ™¯å›¾çš„åŸºç¡€åï¼ˆä¸å«æ‰©å±•åï¼‰
                bg_base_name = os.path.splitext(bg_file)[0]

                # æ„å»ºè¾“å‡ºæ–‡ä»¶åï¼šæºæ–‡ä»¶å_åœºæ™¯.jpg
                output_img_path = os.path.join(self.output_dir, f"{src_base_name}_{bg_base_name}.jpg")

                # ç¡®å®šåœºæ™¯ç±»å‹
                if "3-" in bg_file or "æ–œæ‹" in bg_file:
                    mode = "tilted"
                elif "4-" in bg_file or "é˜´å½±" in bg_file:
                    mode = "shadow"
                elif "5-" in bg_file or "æ°´å°" in bg_file:
                    mode = "watermark"
                elif "6-" in bg_file or "ä¸å®Œæ•´" in bg_file:
                    mode = "incomplete"
                else:
                    mode = "normal"

                # è‡ªåŠ¨/æ‰‹åŠ¨ è·å–èƒŒæ™¯å›¾ä¸­çš„åæ ‡
                detected_corners = detect_document_corners(dst_img_path, self.coord_file, debug=False)

                if detected_corners is None:
                    print(f"   è·³è¿‡: {bg_file} (æœªè·å–åˆ°æœ‰æ•ˆåæ ‡)")
                    continue

                # æ‰§è¡Œåˆæˆ
                try:
                    process_scene_by_filename(src_img_path, dst_img_path, detected_corners,
                                            output_img_path, bg_base_name, mode=mode)
                except Exception as e:
                    print(f"   å¤„ç†å‡ºé”™: {e}")
                    continue

        print("\n" + "#" * 60)
        print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæ¯•ã€‚")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    augmenter = ImageAugmenter(
        backgrounds_dir="backgrounds",
        output_dir="output/03_simulated"
    )
    augmenter.process_images("output/02_images")
